\newcommand{\Lepp}[1]{\mbox{Lepp}(#1)}
\theoremstyle{definition}
\newtheorem{definition}{Definición}[section]

\newtheorem{theorem}{Teorema}


\newtheorem{lemma}[theorem]{Lema}

\newcommand{\ttt}{\texttt}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}
 
\chapter{Introducción}\label{chap:intro}

En el contexto de la astronomía observacional, la medición continua de la magnitud de una fuente, como por ejemplo una estrella o una galaxia, permite la construcción de su curva de luz \cite{warner2006practical}. Una curva de luz es una serie de tiempo de magnitud que permite caracterizar la variabilidad de la fuente en cuestión \cite{percy2007understanding}. A partir de la curva de luz es posible extraer características físicas de la fuente, hacer predicciones sobre su comportamiento futuro y/o clasificar la fuente en alguna de las categorías conocidas. Algunas de estas tareas pueden realizarse de forma automática por medio de modelos de regresión y clasificación ajustados en base a datos, paradigma conocido como Machine Learning \cite{ball2010data, feigelson2012big}. %, o {\it features}, como su periodo y los parámetros de un ajuste sinusoidal, y usar estas características para clarificarla y hacer conclusiones sobre su naturaleza.%, como se ilustra en la figura \ref{fig:ebvsrrl}.
\begin{comment}
    
\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{placeholder.png}
    \caption{Curvas de luz de un sistema binario eclipsante (Figura superior), compuesto por dos estrellas que se eclipsan periódicamente, y una estrella RR Lyrae (Figura inferior), que pulsa gradualmente por un periodo determinado, tienen curvas de luz marcadamente diferentes y es posible diferenciarlas de esta manera.
}
    \label{fig:ebvsrrl}
\end{figure}
\end{comment}

El broker astronómico ALeRCE (Automatic Learning for Rapid Classification of Events) \cite{alerce-intro} tiene el propósito de procesar el flujo de alertas proveniente de telescopios sinópticos de rastreo, tales como el {\it Zwicky Transient Facility} (ZTF) \cite{bellm2019zwicky} o el futuro {\it Vera C. Rubin Observatory} (VRO) con su proyecto principal el {\it Legacy Survey of Space and Time} (LSST) \cite{ivezic2019lsst}.  En este contexto una alerta corresponde a un cambio en brillo o posición de una fuente detectado por el telescopio en base a comparaciones con imágenes de referencia \cite{bellm2019plans}. En promedio ZTF produce 5 alertas por segundo, sin embargo se espera una tasa de 350 alertas por segundo para el caso de VRO, por lo que el procesamiento realizado por un broker debe ser no sólo robusto sino también eficiente y escalable  \cite{ivezic2019lsst}.

El procesamiento que realiza ALeRCE incluye el cálculo de características a partir de las curvas de luz asociadas a las alertas. Estas características son luego utilizadas como entrada para un modelo de Machine Learning que predice la clase a la cual pertenece la fuente \cite{lightcurve-classifier}. Esta información procesada es luego distribuida a la comunidad científica permitiendo que los astrónomos filtren y seleccionen las alertas asociadas a las fuentes de su interés para enfocar sus análisis y hacerles seguimiento \cite{alerce-intro}.

Una de las características más importantes para la clasificación de curvas e luz es su período \cite{lightcurve-classifier}. En particular, el período es clave para distinguir correctamente ciertos tipos de estrellas variables pulsantes \cite{catelan2014pulsating} y sistemas eclipsantes que presentan variaciones regulares en su magnitud \cite{percy2007understanding}. Ciertamente las herramientas más ampliamente utilizadas para realizar análisis frecuencial y estimación de período son la transforma de de Fourier y la función de autocorrelación. Sin embargo estas herramientas no pueden utilizarse directamente en datos con frecuencias de muestreo irregulares, como lo son las curvas de luz astronómicas. Las técnicas de interpolación no son una opción en el caso de las curvas de luz, pues en general las diferencias de magnitud entre instantes sucesivos no cambia monótonicamente. En particular, algunos tipos de fuentes variables pueden presentar oscilaciones con períodos mucho menores a la frecuencia de muestreo promedio \cite{eyer2008variable}.

Por las razones mencionadas anteriormente astrónomos y matemáticos han desarrollado nuevos estimadores para realizar análisis frecuencial que son específicos para series de tiempo con muestreo irregular \cite{scargle1982studies, schwarzenberg1989advantage, zechmeister2009generalised, graham-entropy}. Este estimador, denominado generalmente periodograma, puede describirse como una función $\Theta(\omega)$ evaluada sobre una frecuencia de prueba $\omega$. En general la función $\Theta(\omega)$ indica la fuerza o intensidad de un comportamiento con período $\omega^{-1}$ en una curva de luz en particular. Luego encontrar la frecuencia principal o fundamental de una curva de luz se reduce a evaluar $\Theta(\omega)$ en una grilla de frecuencias candidatas apropiada. 

La diferencia central entre los periodogramas está en la definición de $\Theta(\omega)$. A grandes rasgos se puede hacer la distinción entre periodogramas basados en ajustes de mínimos cuadrados \cite{scargle1982studies, zechmeister2009generalised} y periodogramas basados en la transformación conocida como \textit{epoch folding} \cite{schwarzenberg1989advantage, graham-entropy}

\begin{equation}
\label{eq:phi}
\phi(t) \equiv t/T + \floor{t/T},    
\end{equation}

donde $T=\omega^{-1}$ y $t$ es un instante de observación de una curva de luz. El resultado de aplicar esta transformación es un diagrama de fase o ``curva de luz doblada''. En general, si el período candidato que se usa para doblar la curva es cercano al período real de la fuente entonces el diagrama de fase presentará un patrón ordenado y representativo de la periodicidad del objeto astronómico. En caso contrario el diagrama de fase será similar a ruido sin correlación.

El periodograma utilizado actualmente en ALeRCE es el {\it Multiharmonic Analysis of Variance} (MHAOV) \cite{MHAOV}, el cual se basa en ajustar un modelo sinusoidal con un determinado número de armónicos sobre la curva doblada con una frecuencia $\omega$. En este caso $\Theta(\omega)$ se interpreta como un métrica asociada a la bondad del ajuste entre el modelo sinusoidal y la curva de luz. \cite{MHAOV}. La implementación actual del algoritmo MHAOV se ejecuta completamente en CPU. Adicionalmente se ha detectado que este algoritmo es impreciso para ciertos situaciones que se describirán en las siguientes secciones.

\section{Motivación}\label{sec:motivacion}

El período de una curva de luz es una de sus propiedades más importantes, ya que permite diferenciar entre objetos con curvas de luz similares pero distintos rangos de períodos \cite{eyer2008variable}. Adicionalmente al período de una fuente es relevante para derivar otras propiedades físicas, como su distancia a la Tierra \cite{catelan2004rr} o la masa de las estrellas de un sistema binario. Por otro lado el cálculo del período es actualmente una de las rutinas computacionales más costosas del sistema ALeRCE. Por esto es de gran importancia mejorar su precisión y eficiencia.

\begin{figure}[t]
    \centering
    \includegraphics[scale=0.5]{lightcurve.png}
    \caption{Curva de luz de una binaria eclipsante. El flujo del sistema se reduce cuando una de las estrellas oculta a la otra, pero hay una diferencia entre ambos eclipses, donde el flujo se reduce menos si la estrella que se bloquea es la menos brillante.}
    \label{fig:eclipsantes}
\end{figure}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\textwidth]{./figs/scutti-vs-eb.png}
    \caption{Curva de luz de una $\delta$-Scuti con periodo de $0.097$ dias (Arriba) y una binaria eclipsante con periodo de $0.182$ días (Abajo). Sus curvas de luz son similares pero sus periodos son muy diferentes (Fuente: \href{https://alerce.online/}{ZTF Explorer})}
    \label{fig:scuti-vs-eb}
\end{figure}

Podemos identificar dos áreas en las que el periodograma usado por ALeRCE puede ser mejorado:

\begin{enumerate}
    \item {\bf Eficiencia:} El cálculo de características es el paso computacional más demandante del pipeline del sistema ALeRCE \cite{alerce-intro}. Actualmente ALeRCE procesa alertas de ZTF, sondeo que produce 1.4 TB de datos por noche. El sistema debe ser capaz de mantenerse al ritmo de este volumen de datos. Si bien el sistema actual es capaz de manejar este volumen de alertas es necesario considerar que nuevos sondeos incrementarán exponencialmente esta cantidad. Por ejemplo para el sondeo LSST, el volumen de datos será cerca de 15 TB por noche, por lo que se debe mejorar continuamente la velocidad de estos algoritmos. Actualmente, MHAOV es uno de los algoritmos que toma más tiempo en el cálculo de características, tomando alrededor del $20\%$ del tiempo. Cabe destacar que la implementación de MHAOV utilizada por ALeRCE se ejecuta en CPU y se paraleliza a nivel de curvas de luz. 
    
    Sin embargo debido a que $\Theta(\omega)$ puede también calcularse para cada frecuencia de prueba de forma independiente podemos suponer que el algoritmo se podría ver beneficiado de una implementación masivamente paralela en base a GPU.
    


    \item {\bf Precisión:} Existen fuentes para las cuales MHAOV es particularmente impreciso. Específicamente, MHAOV calcula un periodo igual a la mitad del período real para gran parte de los objetos de tipo binaria eclipsante. Esto se debe a que MHAOV no es lo suficientemente sensible como para distinguir entre ambos eclipses (ver Fig. \ref{fig:eclipsantes}). Esto lleva a que el $2\%$ de las binarias eclipsantes se clasifiquen incorrectamente como estrellas $\delta$-Scuti, ya que estas últimas tienen un rango de periodos menor al de las binarias eclipsantes, pero sus curvas de luz son muy parecidas (ver Fig. \ref{fig:scuti-vs-eb}. Debido a la gran cantidad de binarias eclipsantes, la contaminación en las estrellas $\delta$-Scuti es considerable.

    Esto se podría solucionar considerando otros periodogramas simultáneamente en el clasificador, de manera que este pueda aprender cuando darle más importancia al resultado de uno u otro y así mejorar la clasificación. Otra posible solución es realizar un postproceso que pueda determinar si el resultado de un periodograma es correcto o no. La desventaja de la primera  solución es el costo computacional: calcular otro periodograma podría incrementar considerablemente el tiempo de ejecución necesario para el cálculo de los períodos.
\end{enumerate}


\section{Objetivos}\label{sec:objetivos}

  \subsection*{Objetivo General}\label{sec:obj-g}
  Desarrollar un algoritmo paralelo en GPU que permita determinar el período de un gran volumen de fuentes variables en base a sus curvas de luz, con especial énfasis en aumentar la precisión de este para estrellas binarias eclipsantes, de manera que se logre obtener el periodo real y no alguna fracción de este.

  \subsection*{Objetivos Específicos}\label{sec:obj-e}
  Para cumplir el objetivo de la memoria, se propusieron las siguientes metas:
  \begin{enumerate}
  \item Estudiar y analizar algoritmos para obtener el período ya existentes, empezando por GCE y MHAOV.
  \item Implementar una versión paralela en GPU de MHAOV, denominada GMHAOV, complementando el diseño propio con las técnicas de paralelización usadas en GCE.
  \item Validar y comparar el desempeño de los algoritmos, tanto en términos de tiempo de ejecución como en precisión, usando conjuntos de datos con período conocido.
  \item Evaluar el impacto de incluir el resultado de más de un periodograma  en el clasificador de ALeRCE.
  \item Verificar que al integrar el algoritmo más preciso  en ALERCE es lo suficientemente eficiente en calcular las características y representa una mejora con respecto al algoritmo actual.

  \end{enumerate}
\section{Metodología y resolución}\label{chap:sol}

Ya que este trabajo consistió en desarrollar implementaciones eficientes de algoritmos ya existentes, se pasó por una fase de investigación y evaluación para determinar con qué algoritmos se trabajaría y como se mejorarían. Estos algoritmos son:
\begin{itemize}
    \item {\bf MHAOV:} El algoritmo usado actualmente por ALeRCE. Es necesario saber que tan preciso es y cual es su tiempo de ejecución a fin de compararlo con otros algoritmos. Para mejorar su velocidad de ejecución, se implementó una versión en GPU de este algoritmo, por lo que es muy importante entenderlo a profundidad para poder implementar GMHAOV.
    \item {\bf GCE:} Un periodograma implementado en GPU que usa entropía condicional, una medida de la correlación entre el magnitud y la fase de una curva de luz doblada, y que es considerablemente más rápido que MHAOV. \cite{graham-entropy}
    \item {\bf Métodos para identificar subarmónicos:} Como se describió en la sección \ref{sec:motivacion}, periodogramas como MHAOV suelen identificar subarmónicos del periodo real para algunos objetos astronómicos, por lo que es beneficioso investigar algoritmos que puedan identificar cuando pasa esto y poder encontrar el período real.
\end{itemize}

Se tomó la decisión de implementar GMHAOV en CUDA \cite{cuda}, ya que se tenía experiencia con el desarrollo de algoritmos en GPU en este lenguaje. Esto además permite utilizar el código de GCE como referencia para poder ejecutar código en CUDA desde python. El diseño de GMHAOV se realizó en base a que el cálculo de la medida de confianza es independiente entre curvas de luz y frecuencias, y de hecho el mismo diseño de MHAOV permitía paralelizar este cálculo para cada punto de cada curva de luz.

La implementación de GMHAOV se validó usando el código de generación de curvas de luz disponible en el 
\href{https://github.com/alercebroker/P4J}{repositorio que contiene MHAOV}, y curvas de luz de sets etiquetados (conjuntos cuyas propiedades son conocidas). Como GMHAOV debe presentar exactamente los mismos resultados que su versión secuencial, bastó con comparar los valores de $\Theta(\omega)$ para ambas versiones y asegurarse que estén lo suficientemente cerca. Usando el generador de curvas de luz, fue posible evaluar el tiempo de ejecución de GMHAOV y compararlo con GCE y MHAOV en función del número de frecuencias de prueba y número de curvas de luz.

Con respecto a mejorar la precisión del cálculo del período, en especial en el caso de los estrellas binarias eclipsantes, se implementó un algoritmo que identifica submúltiplos llamado promediado de subarmónicos. Este algoritmo permite discriminar entre señales falsas y señales reales en el periodograma, pero requiere ordenar los valores de $\Theta$ para todas las frecuencias de prueba. Se evalúa el impacto de este postproceso en la precisión del periodograma y además su velocidad de ejecución.

Para estudiar el impacto de los algoritmos implementados en el clasificador, se planea entrenar el clasificador de ALeRCE incluyendo como características el resultado de GMHAOV, GCE y del promediado de subarmónicos. Con esto se espera evaluar el impacto de agregar los resultados de otros periodogramas, como el de GCE, en especial con respecto a las binarias eclipsantes.

\section{Contenido de la memoria}\label{chap:contenido}
\begin{itemize}
    \item {\bf Antecedentes:} Se explican los fundamentos de la computación en GPU, la arquitectura y su modelo de memoria.
    \item {\bf Análisis del software:} Se hace un análisis detallado del software que se utilizó como base en el desarrollo de la solución, incluyendo comparaciones entre sus precisiones y rendimientos. 
    \item {\bf Diseño:} Se describe el diseño de la solución, incluyendo el desarrollo de la interfaz en Python para ejecutar el código de CUDA, el proceso de paralelización de MHAOV y el diseño de un postproceso al periodograma que es capaz de identificar señales falsas.
    \item {\bf Implementación:} Se muestra la implementación de la solución, explicando en detalle y con secciones de código como se llevó a cabo el diseño del capítulo anterior.
    \item {\bf Resultados:} Se describen los métodos de evaluación del rendimiento y precisión de la solución, y se presentan sus resultados y comparaciones con la versión secuencial de MHAOV y el impacto del postproceso que identifica señales falsas en el periodograma.
    \item {\bf Análisis y conclusión:} Se realiza un análisis de los resultados expuestos en la sección anterior, se concluye respecto a los objetivos y se discute el trabajo futuro.
\end{itemize}

\chapter{Antecedentes}\label{chap:antecedentes}
En este capítulo se presentan conceptos y técnicas que son necesarios para poder entender la solución presentada en este documento.
Se empieza por explicar los conceptos fundamentales de la paralelización en GPU, la arquitectura usada en la solución, la manera en la que se maneja la memoria en CUDA y finalmente se habla sobre la técnica de reducción, que permite reducir un arreglo, usando suma o resta por ejemplo, de manera paralela.
\section{Paralelización en GPU}\label{sec:paralelizacion}
La fortaleza de las GPU es que contienen miles de núcleos, donde cada uno puede tratar con un sub-problema pequeño, sacrificando poder de computación de un núcleo individual por poder de paralelización. Sin embargo, una desventaja de las GPU es que, debido a la gran cantidad de unidades de procesamiento, no se deja mucho espacio al caché, como se observa en la Figura \ref{fig:gpu-arch} por lo que los accesos a memoria son muy costosos y se tienen que manejar eficientemente. En una CPU, en cambio, se tiene una pequeña cantidad de núcleos a cambio de que el poder de computación de un núcleo individual es mucho más alto que del de una GPU. \cite{cuda-guide}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figs/gpu-arch.png}
\caption{Distribución de las unidades de procesamiento y memoria en la CPU y GPU. En la GPU, las unidades de control y memoria usan mucho menos espacio que las de procesamiento en comparación con la CPU.}
    \label{fig:gpu-arch}
\end{figure}

Un buen ejemplo de un problema que se beneficia del uso de una GPU en vez de una CPU es la suma de vectores, que es un problema al que se le dice data-paralel, pues la suma de cada componente de los vectores se puede realizar de forma paralela al resto. Este problema es ideal para la GPU pues todas las unidades de procesamiento realizan la misma tarea de baja complejidad y su acceso a la memoria al recuperar los valores a sumar es óptimo pues maximiza el ancho de banda usado.
\section{Arquitectura de CUDA}\label{sec:arquitectura-cuda}
Para la computación en GPU, las dos alternativas más populares son CUDA y OpenCL. La gran desventaja de CUDA es que es exclusivo para las tarjetas de video NVIDIA más modernas, mientras que OpenCL es compatible con una gran cantidad de tarjetas de video, e incluso puede ser ejecutado en CPU. Sin embargo, la documentación y herramientas de CUDA son mucho más extensivas que las de OpenCL. Además, el memorista cuenta con experiencia en CUDA y tanto el memorista como ALeRCE cuentan con GPUs de NVIDIA, por lo que la tecnología elegida para el desarrollo de la solución fue CUDA.

CUDA permite la creación de funciones en C++ llamadas kernel, que se ejecutan paralelamente por todos los núcleos de la GPU. Cada thread puede acceder a información sobre él mismo para determinar con qué datos hará qué computaciones. Como se observa en el Código \ref{code:kernel-ex}, cada thread puede consultar su id.

\begin{lstlisting}[
language=C++,
label={code:kernel-ex},
caption=Kernel que suma los componentes i de los arreglos A y B y lo guarda en el arreglo C]
__global__ void VecAdd(float* A, float* B, float* C)
{
    int i = threadIdx.x;
    C[i] = A[i] + B[i];
}
\end{lstlisting}
Cada thread puede ser identificado en un índice de threads de 1, 2 o 3 dimensiones. Los threads se organizan en bloques de las dimensiones correspondientes, permitiendo una asociación natural entre los threads y arreglos, matrices y volumenes, pero con la restricción de que el número de threads en un bloque no puede superar cierto número, el cual es 1024 para las GPUs de los últimos años, como la usada en el desarrollo y pruebas en esta memoria. Finalmente, todos los bloques de threads se organizan en una grilla de bloques, como se observa en la figura \ref{fig:cuda-grilla}.

CUDA permite sincronización de la ejecución a nivel de bloques, deteniendo la ejecución de cada thread hasta que todos lleguen a una llamada de la función \texttt{\_\_syncthreads()}. Esto implica una disminución en la eficiencia, pero esta sincronización a veces es necesaria para evitar data races.

Un aspecto a considerar es que las GPU siguen un modelo de mismas instrucciones, datos distintos, o SIMD ({\textit Same Instructions Multiple Data}). Esto significa que todos los threads deben ejecutar las mismas instrucciones, lo que se traduce en un impacto en la eficiencia en el caso de los condicionales, pues los threads deben ejecutar todas las instrucciones independiente del resultado del condicional. En el peor de los casos, la mitad de los threads desperdician tiempo en ejecutar instrucciones cuyos resultados se descartan.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figs/cuda-grilla.png}
    \caption{Una grilla se divide en bloques, y cada bloque se subdivide en threads.}
    \label{fig:cuda-grilla}
\end{figure}
\section{Modelo de memoria de CUDA}\label{sec:modelo-memoria}
En CUDA, cada thread puede acceder a distintos tipos de memoria. La memoria local de los threads es solo visible a este y es la de acceso más rápido, mientras que cada bloque tiene memoria que es visible a todos los threads del bloque. Finalmente, hay una memoria global accesible por todos los threads, pero el acceso es considerablemente más lento. La jerarquía de memoria se aprecia en la Figura \ref{fig:cuda-memoria}.

La CPU solo es capaz de enviar datos a la memoria global, por lo que el kernel es el encargado de acceder a esta y guardar el resultado de la computación en el mismo. Como el acceso a memoria global es el más lento, este se debe realizar de forma eficiente aprovechando el ancho de banda de la GPU.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{figs/cuda-memoria.png}
    \caption{Jerarquía de memoria de CUDA.}
    \label{fig:cuda-memoria}
\end{figure}

\section{Reducción en GPU}\label{sev:reduccion}
Una técnica de paralelización muy usada es la reducción, que, acorde a su nombre, sirve para reducir un o múltiples arreglos a un solo valor usando una operación. Un ejemplo sería sumar todos los valores de un arreglo.

En la figura \ref{fig:cuda-reduccion} se encuentra un ejemplo de reducción para un arreglo en la memoria de un bloque. En cada paso, se van acumulando los valores por cada thread hasta que en el paso final el resultado de la reducción se encuentra en el primer elemento del arreglo. Existen otros métodos de reducción pero se usa este por ser el más simple de implementar \cite{harris-reduction}.

Si es que se quiere reducir un arreglo que se procesa en varios bloques, es buena idea empezar reduciendo las partes del arreglo que corresponden a cada bloque, y operar los resultados individuales de todos los bloques en CPU, pues CUDA no ofrece una manera de sincronizar bloques.

\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\textwidth]{figs/reduccion.png}
    \caption{Pasos de la reducción, \cite{harris-reduction}.}
    \label{fig:cuda-reduccion}
\end{figure}


\chapter{Análisis del software}\label{chap:analisis}

En este capítulo, se entregan los detalles del pipeline de ALeRCE y de los algoritmos estudiados durante el curso de la memoria, es decir MHAOV y GCE.

\section{El pipeline de ALeRCE}\label{sec:alerce-pipeline}

El sistema de ALeRCE recibe un flujo de alertas desde ZTF, que contiene varios datos de la observación como la magnitud en distintas bandas y la posición del objeto, entre otros. La Figura \ref{fig:pipeline} muestra un esquema del pipeline de ALeRCE. A continuación se describe cada uno de los bloques diagrama:
\begin{enumerate}
    \item  {\bf S3 upload:} Se suben los paquetes de alertas al servicio de almacenamiento de AWS S3 para uso posterior.
    \item {\bf Cross match:} Se utiliza la posición de la alerta para buscar coincidencias con catálogos externos y obtener más información sobre el objeto.
    \item {\bf Stamp classifier:} Las imágenes de los objetos nuevos son clasificadas utilizando un modelo de aprendizaje profundo \cite{carrasco2020alert}.
    \item {\bf Preprocessing:} Se realizan correcciones a la magnitud y se calculan estadísticas simples de las curvas de luz.
    \item {\bf Light curve features:} Se calculan las características para las curvas de luz con más de 6 puntos. Entre ellas se incluye el período.
    \item {\bf Light curve classifier:} Se clasifica el objeto con las características calculadas en el paso anterior utilizando un ensamble de árboles de decisión con compensación de desbalance de clases \cite{lightcurve-classifier}. 
    \item {\bf Outliers:} Se aplica un algoritmo de detección de outliers (manuscrito en preparación) para identificar las curvas de luz que pueden ser particularmente interesantes y que no correspondan a las clases incluidas en el dataset de entrenamiento de los clasificadores.
    \item {\bf ALeRCE stream:} Se reportan las curvas de luz a la comunidad en un stream. Esto incluye la clasificación de las curvas de luz y las características calculadas.
\end{enumerate}

\begin{figure}[t]
    \centering
    \includegraphics[scale=0.45]{pipeline.png}
    \caption{Pipeline de ALeRCE \cite{alerce-intro}. En el procesamiento realizado al stream de alertas de ZTF se encuentra el cálculo de características (LC features) a partir de las curvas de luz corregidas. El período se calcula en dicha etapa del pipeline.}
    \label{fig:pipeline}
\end{figure}

\section{Diseño de MHAOV}\label{sec:arquitectura-mhaov}

El algoritmo MHAOV usa como medida de confianza la calidad del ajuste de una serie trigonométrica con un determinado número de armónicos a las magnitudes de la curva de luz. El algoritmo asume que las observaciones $X$ son la suma de la señal $F$ y el error $E$, de tal manera que la observación $k$ es $X_k= F_k+E_k$. La forma de la señal $F^{(N)}$ es una serie de Fourier con $N$ armónicos. Con el fin de descomponer la señal en sus componentes, definimos el polinomio $\Psi_{2N}(z)$, de manera que para una frecuencia de prueba $\omega$, los argumentos del polinomio tienen la forma $z_k = e^{i \omega}$, y se asocian a la $k$-ésima observación, y su valor para $z_k$  es $\Psi_{2N}(z_k)=z_k^N F(t_k)$). Notamos que en un espacio de Hilbert un polinomio de grado $N$ puede ser descompuesto en función de una base ortonormal del espacio $\{\Phi\}_{n=1,..,N}$
\begin{align}
    \Psi_N(z) &= \sum_{n=1}^{N} c_n \Phi_n(z)
,\end{align}
donde el producto interno está definido como
\begin{align}
    (\Phi, \Psi) &= \sum_{k=1}^{K} g_k \Phi(z_k) \overline {\Psi(z_k)} \label{eq:scalar-product}\\
    g_k &\approx \frac{1}{\mbox{Var}\{X_k\}} \nonumber 
.\end{align}

Esta base se puede obtener de manera iterativa como se muestra a continuación
\begin{align}
    \tilde{ \Phi }_0(z)  &= 1 \\
    \tilde{ \Phi }_{n+1}(z)  &= z \tilde{ \Phi}_n-\alpha_n z^n \overline{\tilde{\Phi}_n(z) } \label{eq:recurrence} \\ 
\Phi_n(z) &= \frac{\tilde{ \Phi}_n(z) }{\sqrt{(\tilde{\Phi}_n, \tilde{\Phi}_n)}}\\
\alpha_n &= \frac{(z\tilde{\Phi}_n, \tilde{\Phi}_n }{(z^n \overline{\tilde{\Phi}_n}, \tilde{\Phi}_n)} \label{eq:alpha} \\
c_n &= \frac{(\Psi, \tilde{\Phi}_n)}{\sqrt{(\tilde{\Phi}_n, \tilde{\Phi}_n)}} \label{eq:c}
.\end{align}

Para MHAOV, la medida de confianza se basa en estimadores de la varianza de $F$ y $E$, y se define como $\Theta \equiv \widehat{\mbox{Var}} \{F\}/\widehat{\mbox{Var}} \{E\}$. Si consideramos la descomposición en funciones base anterior la expresión tiene la forma (Para mas detalle ver \cite{MHAOV})
\begin{align}
    \Theta(\omega) &= \frac{(K - 2N - 1) \sum_{n=0}^{2N} |c_n|^2}{2N[(X,X)- \sum_{n=0}^{2N} |c_n|^2]} \label{eq:theta} 
.\end{align}
El procedimiento para calcular la medida de confianza es entonces el siguiente:
\begin{enumerate}
    \item Fijar los valores iniciales para la recurrencia, $n=-1$, $\tilde{\Phi}_{-1} = 1/z$, y $\alpha_{-1}=0$.
    \item Usar \eqref{eq:recurrence} para encontrar el siguiente valor de $\tilde{\Phi}_n$
    \item Usar \eqref{eq:scalar-product} para calcular los valores de \eqref{eq:alpha} y \eqref{eq:c}.
    \item Volver al paso 2, iterando esto $N$ veces.
    \item Calcular $\Theta(\omega)$ usando \ref{eq:theta}.
\end{enumerate}
    
\begin{algorithm}[H]
\caption{MHAOV}\label{alg:mhaov}
\begin{algorithmic}[1]
    \State $wmean \gets \text{weighted\_mean}(mag, err, N)$ \Comment{weighted mean}
\For{$i \gets 1$ to $N$}
\State $wvar \gets wvar + (mag[i] - wmean)^{2}/err[i]^{2}$ \Comment{weighted variance $(X, X)$}
\EndFor
\State $\Theta \gets 0$
\For{\texttt{$i \gets 1$ to $N$}}\Comment{Inicialización de variables}
    \State $\phi \gets 2 \pi (mjd[i]*\omega - \floor{mjd[i]*\omega})$
    \State $z_r = \cos(\phi)$ \Comment{Inicialización de $z$}
    \State $z_i = \sin(\phi)$ 
    \State $zn_r = 1$ 
    \State $zn_i = 0$
    \State $p_r = 1/err[i]$
    \State $p_i = 0$
    \State $cf_r = (mag[i] - wmean)\cos(K * \phi) / err[i]$
    \State $cf_i = (mag[i] - wmean)\sin(K * \phi) / err[i]$
\EndFor
\For{$j \gets 1$ to 2$K + 1$}
    \State $sn, al_r, al_i, sc_r, sc_i \gets 0$

        \For{\texttt{$i \gets 1$ to $N$}}
    \State $sn \gets sn + {p_r}^{2}+ {p_i}^{2}  $
    \State $al_r \gets al_r (z_r[i] \cdot  p_r[i] - z_i[i] \cdot  p_i[i])/err[i]$ \Comment{Siguiente valor de de $\alpha$}
        \State $al_i \gets al_i + ( z_r[i] \cdot  p_i[i] + z_i[i] \cdot  p_r[i])/err[i]$
        \State $sc_r \gets sc_r + p_r[i] \cdot  cf_r[i] + p_i[i] \cdot  cf_i[i]$ \Comment{Siguiente valor de $c$}
        \State $sc_i \gets sc_i + p_r[i] \cdot  cf_i[i] - p_i[i] \cdot  cf_r[i]$
    \EndFor
    \State $sn \gets \max(sn, 10\cdot {-9})$
    \State $al_r \gets al_r/sn$
    \State $al_i \gets al_i/sn$
    \State $\Theta \gets \Theta + ({sc_r}^{2} + {sc_i}^{2})/sn$
    \For{$i \gets 1$ to $N$}
        \State $s_r \gets al_r \cdot zn_r[i] - al_i \cdot zn_i[i]$
        \State $s_i \gets al_r \cdot zn_i[i] + al_i \cdot zn_r[i]$
        \State $tmp \gets p_r[i]\cdot z_r[i] - p_i[i]\cdot z_i[i] - s_r\cdot p_r[i] - s_i\cdot p_i[i]$
        \State $p_i \gets p_r[i]\cdot z_i[i] - p_i[i]\cdot z_r[i] - s_r\cdot p_i[i] - s_i\cdot p_r[i]$ \Comment{Actualizar el valor de $\Phi_n$}
        \State $p_r \gets tmp$
        \State $tmp \gets zn_r[i] \cdot z_r[i] - zn_i[i] \cdot z_i$
        \State $zn_i \gets zn_i[i] \cdot z_r[i] + zn_r[i] \cdot z_i$ \Comment{Actualizar el valor de $z^{n}$}
        \State $zn_r \gets tmp$
    \EndFor
\EndFor
\State \Return $(K-2N-1)\cdot \Theta / (2N\cdot \text{max}(wvar - \Theta, 10^{-9}))$

\end{algorithmic}
\end{algorithm}

\section{Diseño de GCE}\label{sec:gce}
El algoritmo de Conditional Entropy (CE) se basa en determinar si existe una correlación entre la magnitud y la fase para una curva doblada de acuerdo a cierta frecuencia. El algoritmo empieza por normalizar los valores de la magnitud y doblar la curva respecto a un periodo $p$, de forma que los valores de magnitud $m(\phi_i)$, con $\phi$ definido de acuerdo a la ecuación \ref{eq:phi}, se encuentren en un cuadrado unitario en el espacio $(m, \phi)$ que se particiona en $k$ secciones en magnitud y en $l$ secciones en fase. Esto se hace para poder calcular la entropía condicional $H_c$, que se define como
\begin{equation}
\label{eq:ce}
H_c = \sum_{i, j} p(m_i, \phi_j)\ln \left ( \frac{p(\phi_j)}{p(m_i, \phi_j)} \right )
\end{equation}
donde $p(m_i, \phi_j)$ es la probabilidad de ocupación para la $i$-ésima partición en magnitud y la $j$-ésima partición en fase, y $p(\phi_j)$ es la probabilidad solo para la $j$-ésima partición en fase. Para GCE, se usan particiones rectangulares y la probabilidad de ocupación se calcula contando la cantidad de puntos por partición y dividiendo esta cantidad por la cantidad total de puntos \cite{graham-entropy}.

Como el cálculo de $H_c$ se realiza para cada frecuencia de prueba y para cada curva, GPU-Accelerated Conditional Entropy (GCE) paraleliza este proceso, calculando una combinación de curva y frecuencia de prueba para cada thread de la GPU. GCE se puede encontrar en \href{https://github.com/mikekatz04/gce}{este repositorio }.


\section{Comparación de MHAOV vs GCE}\label{sec:mhaov-vs-gce}
Se realizó una comparación de MHAOV y GCE usando sets etiquetados, que son archivos con información sobre objetos, incluyendo su clase y periodo. El propósito de esta composición fue evaluar el impacto de crear un periodograma con la precisión de MHAOV pero con un tiempo de ejecución comparable con el de GCE.

Los tests realizados midieron el tiempo de ejecución y la precisión de cada algoritmo usando curvas de luz con mas de 20 puntos, y fueron realizados en un computador con un procesador Intel Core i7-9750H de 12 núcleos lógicos y una GPU Nvidia GeForce 1660 Ti con 6GB de memoria. MHAOV fue ejecutado con $8$ threads en paralelo en CPU, mientras que GCE fue ejecutado en GPU.

Para el primer test, se usaron alrededor de 8500 estrellas RR Lyrae, que tienen curvas suaves y periodos marcados, y en las tablas \ref{table:tiempos-rrl} y \ref{table:precision-rrl} se encuentran los resultados.
\begin{table}[H]
\caption{Tiempos de ejecución total y por curva para ambos algoritmos, usando el mismo conjunto de datos.}
    \begin{tabular}{|c|c|c|}
    \hline
    Algoritmo & Tiempo de ejecución {[}s{]} & Tiempo por curva {[}ms{]} \\ \hline
    GCE       & 85                          & 32                        \\ \hline
    MHAOV     & 629                         & 242                       \\ \hline
    \end{tabular}
    \label{table:tiempos-rrl}
\end{table}

\begin{table}[H]
\caption{Clasificación en porcentajes para los valores del periodo calculado respecto al real. Acierto significa que estos son similares, Múltiplo que el calculado es un múltiplo del original, Submúltiplo que es una fracción del original, Alias que es un alias del original, es decir, que se ajusta igualmente bien a los datos debido a su naturaleza discreta, y Otro para cualquier otro valor del periodo calculado.}
\begin{tabular}{|c|c|c|c|c|c|}
    \hline
    Algoritmo & Acierto & Múltiplo & Submúltiplo & Alias & Otro \\ \hline
    GCE       & 69.5  & 1.7      & 1.8         & 1.7   & 25.3  \\ \hline
    MHAOV     & 88.8  & 1.0      & 0.2         & 1.1   & 8.7   \\ \hline
    \end{tabular}
    \label{table:precision-rrl}
\end{table}
La segunda prueba se hizo con binarias eclipsantes, y la comparación de la precisión de ambos algoritmos está en la Tabla \ref{table:precision-eb}. Notemos que si multiplicamos los periodos obtenidos por $2$, obteniendo el periodo original si es que se había obtenido la mitad de este inicialmente, los resultados cambian a los resultados de la Tabla \ref{table:precision-corrected}, pero aún así observamos cierto grado de contaminación, y al hacer esto estamos obteniendo el periodo equivocado para binarias eclipsantes donde la diferencia entre los eclipses es muy significativa.


\begin{table}[H]
\caption{Clasificación en porcentajes para los valores del periodo calculado respecto al real para las binarias eclipsantes.}
\begin{tabular}{|c|c|c|c|c|c|}
    \hline
    Algoritmo & Acierto & Múltiplo & Submúltiplo & Alias & Otro \\ \hline
    GCE     & 0.42  & 93.30      & 0.00         & 0.00   & 6.28   \\ \hline
    MHAOV       & 11.1  & 55.14      & 0.32         & 0.56   & 32.92  \\ \hline
    \end{tabular}
    \label{table:precision-eb}
\end{table}

\begin{table}[H]
\caption{Comparación entre ambos algoritmos para las tres situaciones: usando RR Lyrae, binarias eclipsantes, y multiplicando por $2$ el periodo obtenido por los algoritmos para binarias eclipsantes.}
\begin{tabular}{|c|c|c|c|c|}
\hline
Prueba & \begin{tabular}[c]{@{}c@{}}Ambos\\ aciertan\\ {[}\%{]}\end{tabular} & \begin{tabular}[c]{@{}c@{}}MHAOV acierta,\\ GCE no {[}\%{]}\end{tabular} & \begin{tabular}[c]{@{}c@{}}GCE acierta,\\ MHAOV no\\ {[}\%{]}\end{tabular} & \begin{tabular}[c]{@{}c@{}}Ninguno\\ acierta \\ {[}\%{]}\end{tabular} \\ \hline
RR Lyrae & 61.40 & 27.40 & 3.40 & 7.78 \\ \hline
\begin{tabular}[c]{@{}c@{}}Binarias\\ Eclipsantes\end{tabular} & 0.20 & 0.22 & 10.86 & 88.72 \\ \hline
\begin{tabular}[c]{@{}c@{}}Binarias\\ Eclipsantes\\ (Ajustado)\end{tabular} & 10.46 & 82.46 & 0.60 & 6.48 \\ \hline
\end{tabular}
\label{table:precision-comparison}
\end{table}




\begin{table}[H]
\caption{Precisión de MHAOV después de multiplicar los periodos obtenidos por $2$}
\begin{tabular}{|c|c|c|c|c|c|}
    \hline
    Algoritmo & Acierto & Múltiplo & Submúltiplo & Alias & Otro \\ \hline
    2 $\cross$ GCE       & 54.50  & 0.30      & 11.88         & 1.30   & 32.02  \\ \hline
    2 $\cross$ MHAOV       & 92.92  & 0.32      & 0.42         & 0.14   & 6.20  \\ \hline
    \end{tabular}
    \label{table:precision-corrected}
\end{table}

De las Tablas \ref{table:tiempos-rrl} a \ref{table:precision-corrected}, notamos que GCE es más rápido pero significativamente menos preciso que MHAOV. Esto incluye el caso de submúltiplos, donde se esperaba que GCE redujera dichos casos puesto que es un algoritmo que no ajusta un serie de Fourier. Al no ajustar una serie trigonométrica se espera que su desempeño sea superior en curvas de luz con formas no sinusoidales como lo son las estrellas binarias eclipsantes. 

La Tabla \ref{table:precision-comparison} muestra que el porcentaje de curvas de luz de GCE acierta y MHAOV falla es del  $3.4\%$ para RR Lyrae y $0.60\%$ para las estrellas binarias eclipsantes despúes de ajustar el periodo. Este último valor pudiera ser significativo debido la gran cantidad de binarias eclipsantes que existen. De estas pruebas se concluye que no es adecuado simplemente reemplazar MHAOV por GCE en ALeRCE, ya que se perderá demasiada precisión. Por otro lado implementar una versión paralela de MHAOV, que sean tanto o más rápida como GCE, será claramente beneficioso.


\chapter{Diseño}\label{chap:diseño}
A continuación se describe el detalle del diseño de la solución, empezando por explicar el proceso de paralelización de MHAOV y luego el detalle del algoritmo de promediado de subarmónicos.

\section{Ejecución de código de CUDA usando python}\label{sec:python-cuda}
Ejecutar código de CUDA directamente desde python requiere del paquete \texttt{cupy}, para enviar las curvas de luz a la memoria de la GPU, y de \texttt{cython}, para realizar llamadas a la función en $C$ que ejecuta el kernel desde python. Para poder compilar el código, se debe escribir un script en python que incluya correctamente las librerias, cambiar el método de compilación para incluir CUDA y que indique las arquitecturas para las cuales se debe realizar la documentación. Afortunadamente, el código de GCE tiene una estructura muy similar a la que se planeaba. GCE ofrece una interfaz en python desde la cual se pueden hacer llamadas al kernel, por lo que se usó el código de GCE como base para el script de compilación y para la clase de python encargada de la preparación de los datos para ser enviados a la memoria de la GPU.

\section{Paralelización de MHAOV}\label{sec:paralelización}
Como se expuso en la sección \ref{sec:motivacion}, MHAOV puede ser paralelizado a nivel de las curvas de luz y las frecuencias de prueba, ya que los valores $\Theta(\omega)$ son independientes entre sí. Adicionalmente, de la descripción del algoritmo en la sección \ref{sec:arquitectura-mhaov} se observa que los ciclos que iteran por el largo de la curva de luz también se pueden paralelizar.

En el Algoritmo \ref{alg:gmhaov} se presenta en pseudocódigo una paralelización de MHAOV. En las lineas 2 a 3 se inicializa el valor de $\Theta$, y luego se calcular el valor de {\textit wmean} y {\textit wmvar}, que requieren sumar los aportes de cada punto de la curva de luz a ellos, usando reducción. Esto requiere sincronizar el bloque en la linea 6 pues el valor de {\textit wmvar} depende del valor de {\textit wmean}. Para el primer ciclo de las lineas 6 a 16 del Algoritmo \ref{alg:mhaov}, se inicializa el valor de cada arreglo por hilo en la linea 9 del algoritmo \ref{alg:gmahov}, el ciclo sobre $j$ de MHAOV de la linea 17 del Algoritmo \ref{alg:mhaov} no se paraleliza pues se ejecuta no más de 10 veces en la práctica y los resultados de un paso dependen del anterior. Para el ciclo de la linea 19 del Algoritmo \ref{alg:mhaov}, se puede calcular el aporte de cada paso a los valores de las variables, y luego utilizar reducción para sumar estos aportes y usar los resultados para calcular el incremento en $\Theta$ luego de sincronizar el bloque para no obtener valores indeterminados. Todo esto corresponde a las lineas 12 a 19 del Algoritmo \ref{alg:gmhaov}. Para el ciclo de la linea 30 del Algoritmo \ref{alg:mhaov}, simplemente se actualizan los valores que corresponden a cada hilo, ya que ellos son independientes entre sí.

Notar que es necesario coordinar los threads en ciertos puntos del kernel para evitar data races. A continuación se presenta el pseudo-código del kernel de GMHAOV, siendo análogo al código presentado en la Sección \ref{sec:arquitectura-mhaov}:

\begin{algorithm}[H]
\caption{GMHAOV}\label{alg:gmhaov}
\begin{algorithmic}[1]
    \Function{GMAHOVKernel}{$lc_i$, $\omega_i$, $i$}
    \If{$i == 0$}
        \State $\Theta \gets 0$
    \EndIf
    \State $wmean \gets$ cálculo paralelo de los aportes de cada punto y suma por reducción 

    \State \_\_syncthreads()

    \State $wmvar \gets$ cálculo paralelo de los aportes de cada punto y suma por reducción 

    \State \_\_syncthreads()
    \State $z_r, \ z_i, \ z_n, \ p_r, \ p_i, \ cf_r, \ cf_i \gets$ valores inciales según $mjd[lc_i, i]$, $err[lc_i, i]$ y $mag[lc_i, i]$

    \State \_\_syncthreads()
    \For{$j \gets 0$ to $2K + 1$}
        \State $al_r, \ al_i, \ sc_r, \ sc_i, \ sn \gets$ suma de los aportes de cada punto por reducción

    \State \_\_syncthreads()
        \If{$i == 0$}
            \State $\Theta \gets \Theta + ({sc_r}^{2} + {sc_i}^{2})/sn$
        \EndIf
        \State $s_r, \ s_i, \ p_r, \ p_i, \ zn_i, \ zn_r \gets$ Valores actualizados usando $al_r, \ al_i, \ zn_r, \ zn_i, \ p_r, \ p_i, \ z_r$ y  $z_i$

    \State \_\_syncthreads()
    \EndFor
\State  $\Theta \gets (K-2N-1)\cdot \Theta / (2N\cdot \text{max}(wvar - \Theta, 10^{-9}))$
    \EndFunction
\end{algorithmic}
\end{algorithm}

Como las curvas de luz son independientes entre sí y estas tienen en promedio $150$ puntos, se pueden guardar completamente en memoria compartida para cada bloque y así acceder a memoria global sólo para obtener las curvas y su número de puntos. Además de las curvas de luz, se deberá usar la memoria local para la reducción de 8 variables, usando 8 arreglos del largo de la curva de luz más larga. 

\section{Promediado de subarmónicos}\label{sec:subarmonicos-diseno}
El promediado de subarmónicos es descrito en \cite{graham-entropy}, pero el código no está disponible así que se tuvo que implementar este algoritmo en base a la descripción en el paper citado. La idea del promediado de subarmónicos, es que si en el periodograma se tiene una señal real en $\Theta(\omega)$, entonces el periodograma tendrá un peak relevante en $\frac{\omega}{2}$. De esta manera, si se promedia el valor de $\Theta$ en $\omega$ y en $\frac{\omega}{2}$, se debe seguir teniendo un valor significativo, de lo contrario se tenía una señal falsa y la frecuencia real está en otra parte.

Para poder implementar esto como algoritmo, es necesario ordenar los valores de $\Theta$ para obtener las frecuencias más relevantes. El costo computacional de esto se puede reducir buscando máximos o mínimos locales de $\Theta$ escaneando el arreglo de valores y marcando aquellos que son mayores que sus vecinos, lo cual tiene un costo computacional de $\mathcal O(N_\omega)$, con $N_\omega$ la cantidad de frecuencias de prueba, y luego ordenando estos valores. El costo computacional seguirá siendo de $\mathcal O (N_\omega \ln N_\omega)$, pero el ordenamiento podrá ignorar la gran mayoría de las frecuencias. Luego se elijen las frecuencias con mayor valor de $\Theta$, y se marcan como señales significativas.

Se establece un criterio simple para determinar si una señal significativa es real: Si existe otra señal significativa cerca de la mitad de su frecuencia asociada, entonces se promedian los valores de $\Theta$ y se le asigna como puntaje a la frecuencia. Si no existe esta señal, entonces su puntaje es nulo. Así se elije la frecuencia asociada a la señal con el mayor puntaje y se eliminan las señales falsas. Asociarle este puntaje al resultado del periodograma es conveniente pues se puede usar posteriormente como característica en el clasificador.

\chapter{Implementación}\label{chap:implementación}
En este capítulo se detalla la implementación de la solución, empezando por como se preparan los datos en python para ser cargados en la memoria de la GPU, la implementación del kernel y finalmente el promediado de subarmónicos.
\section{Preparación de los datos en python}\label{sec:preparacion-datos}
Se crea la clase de python GMHAOV, basada en GCE, con una función que recibe las curvas de luz, las frecuencias de prueba, la cantidad de curvas de luz para las cuales se calculará el periodograma y el tamaño de lote en el que se dividirán las curvas de luz para no sobrecargar la memoria, como se observa en el Código \ref{code:data-prep-1}. Se ignoran varias funciones de GCE que no se reimplementaron en GMHAOV, ya que las interfaces que ofrecen son compatibles con cualquier periodograma, como por ejemplo la función que encuentra el máximo o mínimo del mismo.
\begin{lstlisting}[
language=Python,
label={code:data-prep-1},
caption=Primera parte de la inicialización]
def batched_run_const_nfreq(self, lightcurves, batch_size, freqs):
...
    # split by light curve batches
    split_inds = []
    i = 0
    while i < len(lightcurves):
        i += batch_size
        if i >= len(lightcurves):
            break
        split_inds.append(i)

    lightcurves_split = np.split(lightcurves, split_inds)
...
    bf = []
    per_vals = []
    for i, light_curve_split in iterator:

        # run one light curve batch
        out = self._single_light_curve_batch(
            light_curve_split,
            freqs)
...
\end{lstlisting}

Antes de realizar el cálculo del periodograma es necesario determinar el largo de cada curva de luz y el largo máximo entre todas las curvas de luz usando el ciclo de la linea 6 del bloque de código \ref{code:data-prep-2}.  Estos valores son necesarios para determinar el númedo de threads de cada bloque, pues estos deben tener a lo menos un thread por punto de la curva de luz. Luego en las lineas 17 a 21 se crean arreglos para los tiempos, magnitudes y errores para las curvas de luz, donde cada arreglo tiene un largo equivalente al de la curva más larga, y las entradas adicionales se rellenan con ceros.

Originalmente, GCE realizaba otros cálculos relacionados al binning de las magnitudes y los tiempos, además de considerar los valores de la derivada del periodo $\dot p$, pero esto fue removido ya que MHAOV no es un algoritmo incluya el cálculo de este valor, y el código fue adaptado para funcionar sin esto.
\begin{lstlisting}[
language=Python,
label={code:data-prep-2},
caption=Segunda parte de la inicialización]

# determine maximum length of light curves in batch
# also find minimum and maximum magnitudes for each light curve
max_length = 0
number_of_pts = np.zeros((len(light_curve_split),)).astype(int)
for j, lc in enumerate(light_curve_split):
    number_of_pts[j] = len(lc)
    max_length = max_length if len(lc) < max_length else len(lc)
light_curve_arr = np.zeros((len(light_curve_split), max_length, 3))
logging.info(f"Number of points {number_of_pts}")

# populate light_curve_arr
for j, lc in enumerate(light_curve_split):
    light_curve_arr[j, : len(lc)] = np.asarray(lc)

# separate time and mag info
light_curve_times = light_curve_arr[:, :, 0]

light_curve_mags = light_curve_arr[:, :, 1]

light_curve_errs = light_curve_arr[:, :, 2]
\end{lstlisting}

Luego en la lineas 2 a 10 del Código \ref{code:data-prep-3} se aplanan los arreglos para formar tres arreglos que contienen los datos de todas las curvas, y se cargan en la memoria de la GPU usando la función de cupy \texttt{xp.asarray} junto con el arreglo que contiene las frecuencias de prueba, el arreglo que contendrá los resultados del periodograma y el arreglo que contiene el número de armónicos con el que se correrá el periodograma para cada curva, el cual por ahora se inicializa con solo unos. En la linea 24 se llama al envoltorio de la función que llama al kernel con los arreglos creados y otros datos como el número de frecuencias y el número de curvas de luz.
\begin{lstlisting}[
language=Python,
label={code:data-prep-3},
caption=Tercera parte de la inicialización]
        # flatten everything
        light_curve_times_in = (
            xp.asarray(light_curve_times).flatten().astype(self.dtype)
        )

        light_curve_mags_in = xp.asarray(light_curve_mags.flatten()).astype(
            self.dtype
        )

        light_curve_errs_in = xp.asarray(light_curve_errs.flatten()).astype(
            self.dtype
        )
        number_of_pts_in = xp.asarray(number_of_pts).astype(xp.int32)

        freqs_in = xp.asarray(freqs).astype(self.dtype)

        per_vals_out_temp = xp.zeros(
            (len(freqs_in) * len(light_curve_times),), dtype=self.dtype
        )

        max_num_pts_in = number_of_pts_in.max().item()
        Nharmonics = xp.ones(len(light_curve_times), dtype=xp.int32)

        self.gmhaov_func(
            per_vals_out_temp,
            freqs_in,
            len(freqs_in),
            light_curve_times_in,
            light_curve_mags_in,
            light_curve_errs_in,
            number_of_pts_in,
            Nharmonics,
            len(light_curve_times),
            max_num_pts_in
        )
        per_vals_out_temp = per_vals_out_temp.reshape(
            len(light_curve_times), len(freqs_in)
        )
\end{lstlisting}
En la linea 36 del Código de \ref{code:data-prep-3} se cambia la forma del arreglo con los resultados del periodograma de manera que sea un arreglo de los valores de $\Theta$ para cada curva de luz.
El envoltorio de la función que llama al kernel está escrito en Cython, y usa una decoración que reemplaza los arreglos que recibe la función como argumentos por sus punteros en memoria. En este caso, como los arreglos están en memoria de la GPU, estos son reemplazados por los punteros a su localización en la GPU. Luego, la función en CUDA \texttt{run\_gmhaov}, encargada de hacer las llamadas al kernel, es ejecutada con estos punteros como argumentos.
\begin{lstlisting}[
language=Python,
label={code:cython-wrapper},
caption=Wrapper en Cython]
@pointer_adjust
def run_gmhaov_wrap(per, freqs, num_freqs, mjds, mags, errs, num_pts_arr, Nharmonics_arr, num_lcs, num_pts_max,  wmeans_arr, wvars_arr):
    cdef size_t per_in = per
    cdef size_t freqs_in = freqs
    cdef size_t num_freqs_in = num_freqs
    cdef size_t mags_in = mags
    cdef size_t mjds_in = mjds
    cdef size_t errs_in = errs
    cdef size_t num_pts_arr_in = num_pts_arr
    cdef size_t Nharmonics_arr_in = Nharmonics_arr
    cdef size_t num_lcs_in = num_lcs
    cdef size_t num_pts_max_in = num_pts_max
    run_gmhaov(<fod *> per_in, <fod *> freqs_in, num_freqs_in, <fod *> mags_in, <fod *> mjds_in, <fod *> errs_in,
                             <int *> num_pts_arr_in, <int *> Nharmonics_arr_in, num_lcs, num_pts_max_in, <float *> wmeans_arr_in, <float *> wvars_arr_in)
\end{lstlisting}

\section{Paralelización}\label{sec:paralelización-implementacion}
Como la memoria local usada por cada bloque es variable para cada ejecución, y los arreglos relevantes ya están en la memoria de la GPU, \texttt{run\_gmhaov} es una función relativamente corta, pues no necesita reservar el espacio que cada arreglo usará en memoria local ni mover objetos desde la memoria del host a la del dispositivo. El tamaño de la grilla, determinado en la linea 3 del Código \ref{code:kernel-wrapper}, se escoge como el número de frecuencias en el eje $x$ y el número de curvas de luz en el eje $y$. La memoria de cada bloque, calculada en la linea 6, es el espacio que ocupará cada curva de luz más los arreglos necesarios para hacer las reducciones descritas en la Sección \ref{sec:paralelizacion}.

Como siempre es conveniente tener potencias de $2$ como tamaño de bloque, se aproxima el largo máximo de las curvas de luz a su potencia de $2$ superior más cercana y se elije esta como tamaño de bloque, considerando un valor máximo de $1024$. El objetivo es que cada bloque pueda procesar completamente cada curva de luz. Para curvas de luz con más de $1024$ puntos el kernel podría procesarla completamente, pero en esta implementación se asume que todas las curvas tienen menos de $1024$ puntos.
\begin{lstlisting}[
language=C,
label={code:kernel-wrapper},
caption=Wrapper del kernel]
void run_gmhaov(fod *d_per, fod *d_freqs, int num_freqs, fod *d_mag, fod *d_mjd, fod *d_err,
                 int *num_pts_arr, int *Nharmonics_arr, int num_lcs, int num_pts_max, float *wmeans_arr, float *wvars_arr){
    dim3 griddim(num_freqs, num_lcs, 1); 

    // determine shared memory allocation size
    size_t numBytes = sizeof(fod)*num_pts_max + // magnitude values
                      sizeof(fod)*num_pts_max + // error values
                        sizeof(fod) * num_pts_max + // time values
                        5 * sizeof(fod) * num_pts_max + // sn, scr, sci, alr, ali to sum
                        3 * sizeof(fod) * num_pts_max; // wvar, wmean, w_sum to sum

    int v = num_pts_max;
    // Source for rounder: https://graphics.stanford.edu/~seander/bithacks.html#RoundUpPowerOf2
    v--;
    v |= v >> 1;
    v |= v >> 2;
    v |= v >> 4;
    v |= v >> 8;
    v |= v >> 16;
    v++;
    if (v > 1024) v = 1024;
    kernel<<<griddim, v, numBytes>>>(d_per,
                                                d_freqs, num_freqs,
                                                d_mag, d_mjd,
                                                d_err, num_pts_arr,
                                                Nharmonics_arr, num_lcs,
                                                num_pts_max, wmeans_arr, wvars_arr);
    cudaDeviceSynchronize();
    gpuErrchk(cudaGetLastError());
}
\end{lstlisting}

En el Código \ref{code:kernel}, el kernel empieza por crear el arreglo compartido \texttt{mag\_share}, que tiene el espacio necesario para guardar todos los arreglos locales que se usan en cada bloque. Se define entonces el resto de los arreglos como punteros a las secciones que le corresponden en memoria, listos para ser rellenados por los datos en memoria global, y finalmente se declaran las cantidades que se comparten en todo el bloque.

\begin{lstlisting}[
language=C++,
label={code:kernel},
caption=Inicialización de memoria en el kernel del algoritmo]
    
__global__ void kernel(fod* __restrict__ d_per,
                        fod* d_freqs, int num_freqs,
                        fod* d_mag, fod* d_mjd,
                        fod* d_err, int* num_pts_arr,
                        int* Nharmonics_arr, int num_lcs,
                        int num_pts_max, fod* wmeans_arr, fod* wvars_arr)
    {
    /* Assign the magnitude,error and time values to sections of the shared array */
    extern __shared__ fod mag_share[];
    fod *error_share = (fod*) &mag_share[num_pts_max];
    fod *time_share = (fod*) &error_share[num_pts_max];

    fod *sn_sum = (fod*) &time_share[num_pts_max];

    fod *scr_sum = (fod*) &sn_sum[num_pts_max];
    fod *sci_sum = (fod*) &scr_sum[num_pts_max];
    ...
    __shared__ fod sn;
    __shared__ fod scr;
    __shared__ fod sci;
    ...
\end{lstlisting}
En caso que se haya elegido un tamaño de grilla en el eje $y$ menor al número de curvas de luz, se introduce un ciclo que se asegura que todas las curvas de luz sean procesadas, empezando por $lc_i = \text{blockIdx.y}$. Luego se carga en memoria local la curva de luz actual de forma paralela, y se itera en frecuencias en el eje $x$ de la misma manera que se hace en el eje $y$, empezando por $f_i = \text{blockIdx.x}$. Se definen las variables que se usarán para el cálculo de $\Theta$, y uno de los threads inicializa a $\Theta=0$.
\begin{lstlisting}[
language=C++,
label={code:kernel-2},
caption=Inicialización de variables en el kernel]
    for (int lc_i = blockIdx.y; lc_i < num_lcs; lc_i += gridDim.y){
        int num_pts_current = num_pts_arr[lc_i];
            int current_index = lc_i * num_pts_max + i;
            mag_share[i] = d_mag[current_index];
            error_share[i] = d_err[current_index];
            time_share[i] = d_mjd[current_index]; 
        }
        __syncthreads();
        for (int fi = blockIdx.x; fi < num_freqs; fi += gridDim.x) {
            int idx = threadIdx.x;
            fod zr, zi, znr, zni, pr, pi, cfr, cfi;

            if (idx == 0) aov = 0;
            ...
\end{lstlisting}
Un problema con la implementación de GMHAOV es que si la curva de luz tiene un largo mayor que el tamaño de bloque máximo de $1024$, no es posible cubrirla en el periodograma y el algoritmo deja de funcionar. El algoritmo toma $i=idx$, el $id$ del thread en el bloque, y calcula $wmean$ y $wvar$ encontrando el aporte de cada valor a estos valores y luego usando reducción para encontrar sus valores finales en las lineas 2 a la 11 del código \ref{code:kernel-3}.
\begin{lstlisting}[
language=C++,
label={code:kernel-3},
caption=Cálculo de wmean y wvar en el kernel]
            ...
            w_sum_sum[i] = 1.0 / powf(abs(error_share[i]), 2.0f);
            w_mean_sum[i] = mag_share[i] / powf(abs(error_share[i]), 2.0f); }
            __syncthreads();
            for(int size = NUM_THREADS/2; size > 0; size/=2){
                if(idx < size && (idx + size < num_pts_arr[lc_i])){
                    w_sum_sum[idx] += w_sum_sum[idx + size];
                    w_mean_sum[idx] += w_mean_sum[idx + size];
                }
                __syncthreads();
            }

            if (idx == 0) {
                w_sum = w_sum_sum[0];
                w_mean = w_mean_sum[0];
                w_mean = w_mean / w_sum;
                wmeans_arr[lc_i] = w_mean;
            }
            __syncthreads();
            ...
\end{lstlisting}
Luego se procede de según lo indicado en el Algoritmo 2,  presentado en \ref{sec:arquitectura-mhaov}, siendo la diferencia principal que el algoritmo calcula el aporte de cada punto a los valores de $\alpha$, $c$ y $sn$ desde las lineas 13 a 14 del código \ref{code:kernel-4} y los utiliza para obtener sus valores finales usando reducción entre las lineas 23 y 32. Es necesario sincronizar el bloque después de inicializar las variables, al terminar de calcular los aportes de cada punto, como parte de la reducción, y después de calcular el aporte del ciclo a $\Theta$ en la linea 46. Finalmente se actualizan los valores de $s_r, \ si_i, \ zn_r, \ zn_i, \ p_r$ y $ p_i$ entre las lineas 49 y 58.
\begin{lstlisting}[
language=C++,
label={code:kernel-4},
caption=Loop principal del kernel]
        fod arg = d_freqs[fi] * time_share[i];
            fod phi = 2 * PI * (arg - floor(arg));
            zr = cos(phi);
            zi = sin(phi);
            znr = 1;
            pr = 1 / error_share[i];
            zni = 0;
            pi = 0;
            fod factor = (mag_share[i] - w_mean) / error_share[i];
            cfr = factor * cos(Nharmonics_arr[lc_i] * phi);
            cfi = factor * sin(Nharmonics_arr[lc_i] * phi);

            for (int j = 0; j < (2 * Nharmonics_arr[lc_i] + 1); j++){
                __syncthreads();
                sn_sum[i] = powf(fabsf(pr), 2.0f) + powf(fabsf(pi), 2.0f);

                scr_sum[i] = pr * cfr + pi * cfi;
                sci_sum[i] = pr * cfi - pi * cfr;

                alr_sum[i] = (zr * pr - zi * pi) / error_share[i];
                ali_sum[i] = (zr * pi + zi * pr) / error_share[i];
                __syncthreads();
                for(int size = NUM_THREADS/2; size > 0; size/=2){
                    if(idx < size && (idx + size < num_pts_arr[lc_i])){
                        sn_sum[idx] += sn_sum[idx + size];

                        scr_sum[idx] += scr_sum[idx + size];
                        sci_sum[idx] += sci_sum[idx + size];

                        alr_sum[idx] += alr_sum[idx + size];
                        ali_sum[idx] += ali_sum[idx + size];
                    }
                    __syncthreads();
                }
                if (idx == 0) {
                    sn = sn_sum[0];

                    scr = scr_sum[0];
                    sci = sci_sum[0];

                    alr = alr_sum[0];
                    ali = ali_sum[0];

                    if (sn < 1e-9) sn = 1e-9;
                    alr = alr / sn; ali = ali / sn;
                    aov += (powf(fabsf(scr), 2.0f) + powf(fabsf(sci), 2.0f))/sn;
                }
                __syncthreads();
                fod sr, si;
                fod tmp;
                sr = alr * znr - ali * zni;
                si = alr * zni + ali * znr;
                tmp = pr * zr - pi * zi - sr * pr - si * pi;
                pi = pr * zi + pi * zr + sr * pi - si * pr;
                pr = tmp;
                tmp = znr * zr - zni * zi;
                zni = zni * zr + znr * zi;
                znr = tmp;
            }
\end{lstlisting}
Finalmente, en el Código \ref{code:kernel-5} el primer thread calcula el valor final de $\Theta$, y se coloca en el arreglo que contiene el resultado del periodograma para todas las curvas.
\begin{lstlisting}[
language=C++,
label={code:kernel-5},
caption=Resultado del periodograma]
            if (idx == 0) {
                fod d1 = 2 * Nharmonics_arr[lc_i];
                fod d2 = num_pts_arr[lc_i] - Nharmonics_arr[lc_i] * 2 - 1;
                d_per[lc_i * num_freqs + fi] = d2 / d1 * aov / max(wvar - aov, 1e-9);
            }
\end{lstlisting}

\section{Promediado de subarmonicos}\label{sec:subarmonicos-implementacion}
El periodograma entrega el arreglo \texttt{thetas} que contiene los valores de $\Theta(\omega)$ para cada curva, que puede ser usado para encontrar los máximos locales más relevantes del periodograma. Para esto, se usa la función \texttt{argrelextrema} del paquete Scipy, que encuentra los índices para los cuales $\Theta$ es mayor que sus vecinos a cierta distancia. Estos máximos se ordenan según su valor asociado de $\Theta$ y la función entrega el arreglo con los índices de las frecuencias que representan señales significativas para la curva de luz. Esta función se llama para todas las curvas y los resultados se colocan en un arreglo que contiene el índice de todas las señales significativas, ordenadas por su valor en el periodograma.
\begin{lstlisting}[
language=Python,
label={code:ps-1},
caption=Obtención de candidatos a frecuencia]
def find_local_maxima(theta, n_local_optima=10, order=2):
    local_optima_index = argrelextrema(theta, np.greater, order=order)[0]
    if(len(local_optima_index) < n_local_optima):
        print("Warning: Not enough local maxima found in the periodogram")
    # Keep only n_local_optima
    best_local_optima = local_optima_index[np.argsort(theta[local_optima_index])][::-1]
    if n_local_optima > 0:
        best_local_optima = best_local_optima[:n_local_optima]
    else:
        best_local_optima = best_local_optima[0]
    return best_local_optima
def get_significant_signals(thetas, n_significant_signals = 10, order=2, signal_diff_tolerance = 0.2, sign=-1, spacing=100):
    significant_signals_arr = []
    for theta in thetas:
        local_optima_index = find_local_maxima( -sign * theta, n_significant_signals, order)
        significant_signals_arr.append(local_optima_index)
    return significant_signals_arr
\end{lstlisting}
Este arreglo \texttt{thetas} permite identificar señales reales como se describió en \ref{sec:subarmonicos-diseno}, iterando sobre las señales significativas de todas las curvas de luz. Primero se identifica si es que hay alguna otra señal significativa en la mitad de la frecuencia, si no la hay entonces la señal es falsa y se ignora. En el caso contrario, se le asigna un puntaje igual al promedio del valor de $\Theta$ en la frecuencia de la señal y de su primer subarmónico. Si este puntaje está dentro de un cierto rango de tolerancias ajustable, entonces esta señal se identifica como asociada a la frecuencia real y se pasa a la siguiente curva. Se pueden ignorar las siguientes señales pues como están ordenadas son más débiles que la primera señal real.

En caso de que ninguna de las señales significativas pasen esta prueba, entonces se elige como frecuencia real la primera de la lista. Es importante notar que al asignarle un puntaje a la frecuencia elegida por el periodograma, este se puede usar como característica para el clasificador en vez de tener un corte dado por el usuario.
\begin{lstlisting}[
language=Python,
label={code:ps-2},
caption=Búsqueda de la frecuencia final]
    def get_best_indices(significant_signals_arr, thetas, tol, freqs_test, score_tol_lower=0, score_tol_upper=np.inf):
    best_indices = []
    for lc_i, significant_signals in enumerate(significant_signals_arr):
        scores = []
        for s_i, signal_index in enumerate(significant_signals):
            is_freq_mult = np.abs(freqs_test[signal_index] / 2 - freqs_test[significant_signals]) < tol
            significant_signals_index = np.where(is_freq_mult)[0]
            if len(significant_signals_index) > 0:
                theta_freq_mult = thetas[lc_i][significant_signals[significant_signals_index[0]]]
                theta_freq = thetas[lc_i][signal_index]
                score = (theta_freq + theta_freq_mult)/2
                if score_tol_lower < score < score_tol_upper:
                    # this is the correct signal
                    best_indices.append(signal_index)
                    break
            if s_i == len(significant_signals) - 1:
                best_indices.append(significant_signals[0])
    return best_indices
\end{lstlisting}


\chapter{Resultados}\label{chap:resultados}
En esta sección se detallan los resultados de la validación y evaluación de los algoritmos, y se describe la comparación de rendimiento entre ellos. Todas las pruebas fueron realizadas en un computador con un procesador Intel Core i7-9750H de 12 núcleos lógicos y una GPU Nvidia GeForce 1660 Ti con 6GB de memoria.
\section{Validación de GMHAOV}\label{sec:validacion}
GMHAOV se validó usando el generador de curvas de luz incluido con MHAOV, y se calculó la raíz de la suma de los cuadrados de las diferencias relativas entre los resultados de MHAOV y GMHAOV, y ese valor se dividió por la cantidad de curvas de luz y la cantidad de frecuencias de prueba para obtener el error relativo promedio por curva por valor de $\Theta$. Con $1000$ curvas generadas sintéticamente por el generador de P4J \footnote{\href{https://github.com/alercebroker/P4J}{Repositorio de P4J que incluye el generador}} y $10000$ frecuencias de prueba, este valor corresponde a $4.8 \times 10^{-7}$, lo cual se encuentra dentro de los rangos aceptables.

Usando $1000$ curvas de luz de  RR Lyrae con las que se evaluó inicialmente MHAOV y GCE en el capítulo \ref{sec:mhaov-vs-gce}, y $10000$ frecuencias de prueba, se obtuvo un valor del error cuadrático de $0.063$, lo que corresponde a un error promedio de un $6.3\%$ para cada valor del periodograma. Esto es considerable, y al inspeccionar en qué valores hay una diferencia importante, se observa que hay ciertas curvas de luz problemáticas donde la diferencia entre ambos algoritmos es considerablemente mayor que para otras curvas. Sin embargo, estas curvas problemáticas no presentan ninguna diferencia inmediatamente evidente del resto, ni en su forma ni en su cantidad de puntos, por lo que sería necesario estudiar este problema a fondo.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figs/problemas.png}
    \caption{Resultado del periodograma para MHAOV (Arriba) y GMHAOV (Centro), y la diferencia entre ambos (Abajo).}
    \label{fig:problemas}
\end{figure}
En la Figura \ref{fig:problemas} se pueden apreciar que la diferencia entre ambos periodogramas es notable, en especial en los peaks que están desplazados levemente, pero no es suficiente como para cambiar significativamente la frecuencia que corresponde al máximo. De hecho al comparar la precisión de ambos algoritmos, ésta solamente disminuye desde $80\%$ a $79\%$ para RR Lyrae.

\section{Efecto del promediado de subarmónicos}\label{sec:efectos-subarmonicos-sec}

Se evaluó el efecto en la precisión del GMHAOV y GCE al introducir el promediado de subarmónicos usando los conjuntos de datos mencionados en la Sección \ref{sec:mhaov-vs-gce}. 
\subsection{Promediado de subarmónicos (PS)}
A continuación se presentan los efectos de introducir el promediado de subarmónicos en el cálculo del periodo. 
\subsubsection{RR Lyrae}
En la Tabla \ref{table:rrl-PS}, se observa que si bien PS logra obtener el período correcto para el $0.10\%$ de los objetos, los objetos para los que ya no se tiene el período correcto son casi el doble para ambos algoritmos. De la Tabla \ref{table:rrl-PS-detalle} se puede notar que al aplicar PS en GCE, la cantidad de submúltiplos, o fracción de curvas para las cuales se calcula una fracción, como la mitad o un tercio, del periodo original se reduce casi en un $50\%$, pero la cantidad de múltiplos, o fracción de curvas para las cuales se calcula un múltiplo del periodo, como el doble o el triple, casi se triplica, mientras que en GMHAOV los múltiplos incrementan levemente mientras que los submúltiplos se eliminan completamente.

\begin{table}[H]
\caption{Diferencias en la precisión de GCE y GMHAOV al aplicar promediado de subarmonicos (PS).}
\begin{tabular}{|c|c|c|c|c|}
\hline
Prueba & \begin{tabular}[c]{@{}c@{}}Ambos\\ aciertan\\ {[}\%{]}\end{tabular} & \begin{tabular}[c]{@{}c@{}}Acierta con\\ PS {[}\%{]}\end{tabular} & \begin{tabular}[c]{@{}c@{}}Deja de acertar\\ con PS {[}\%{]}\end{tabular} & \begin{tabular}[c]{@{}c@{}}No acierta\\ nunca {[}\%{]}\end{tabular} \\ \hline
GMHAOV & 90.15 & 0.10 & 0.20 & 9.55 \\ \hline
GCE & 52.10 & 3.70 & 6.70 & 37.50 \\ \hline
\end{tabular}
\label{table:rrl-PS}
\end{table}

\begin{table}[H]
\caption{Detalles de las diferencias en la precisión de GCE y GMHAOV al aplicar promediado de subarmonicos (PS).}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
Prueba & Match & Multiplo & Submultiplo & Alias & Other \\ \hline
GMHAOV & 90.35 & 0.75 & 0.10 & 1.45 & 7.35 \\ \hline
\begin{tabular}[c]{@{}c@{}}GMHAOV\\ con PS\end{tabular} & 90.25 & 0.95 & 0.00 & 1.45 & 7.25 \\ \hline
GCE & 58.80 & 2.10 & 4.45 & 3.60 & 31.05 \\ \hline
\begin{tabular}[c]{@{}c@{}}GCE\\ con PS\end{tabular} & 55.80 & 5.90 & 2.45 & 4.05 & 31.80 \\ \hline
\end{tabular}
\label{table:rrl-PS-detalle}
\end{table}

\subsubsection{Binarias eclipsantes}
De la Tabla \ref{table:eb-PS-detalle}, se observa que al usar PS, se deja de acertar para menos objetos tanto en GMHAOV como en GCE, y en la Tabla \ref{table:eb-PS-detalle} los aciertos de GCE disminuyen al introducir PS, y los de GMHAOV se mantienen igual, pero la cantidad de submúltiplos disminuye en GCE. En este caso, no hay mayor beneficio en introducir PS.

\begin{table}[H]
\caption{Detalles de las diferencias en la precisión de GCE y GMHAOV al aplicar promediado de subarmonicos (PS) para binarias elipsantes.}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
Prueba & Match & Multiplo & Submultiplo & Alias & Other \\ \hline
GMHAOV & 0.20 & 93.55 & 0.00 & 0.00 & 6.55 \\ \hline
\begin{tabular}[c]{@{}c@{}}GMHAOV\\ con PS\end{tabular} & 0.20 & 92.55 & 0.00 & 0.00 & 7.25 \\ \hline
GCE & 9.85 & 44.40 & 0.30 & 0.95 & 44.50 \\ \hline
\begin{tabular}[c]{@{}c@{}}GCE\\ con PS\end{tabular} & 7.75 & 45.56 & 0.10 & 0.80 & 45.85 \\ \hline
\end{tabular}
\label{table:eb-PS-detalle}
\end{table}
\begin{table}[H]
\caption{Diferencias en la precisión de GCE y GMHAOV al aplicar promediado de subarmonicos (PS) para binarias elipsantes.}
\begin{tabular}{|c|c|c|c|c|}
\hline
Prueba & \begin{tabular}[c]{@{}c@{}}Ambos\\ aciertan\\ {[}\%{]}\end{tabular} & \begin{tabular}[c]{@{}c@{}}Acierta con\\ PS {[}\%{]}\end{tabular} & \begin{tabular}[c]{@{}c@{}}Deja de acertar\\ con PS {[}\%{]}\end{tabular} & \begin{tabular}[c]{@{}c@{}}No acierta\\ nunca {[}\%{]}\end{tabular} \\ \hline
GMHAOV & 0.20 & 0.00 & 0.00 & 99.80 \\ \hline
GCE & 7.2 & 0.55 & 2.65 & 89.60 \\ \hline
\end{tabular}
\label{table:eb-PS}
\end{table}

\subsection{Efecto del promediado de armónicos (PA)}\label{sec:efectos-subarmonicos}
Como se observó en algunos periodogramas, usualmente hay una señal significativa en el doble de la frecuencia en vez de la mitad, así que se decide probar el promediado con la medida de confianza en el doble de la frecuencia, y le denominaremos a esto promediado de armónicos (PA).
\subsubsection{RR Lyrae}
De la Tabla \ref{table:rrl-PA}, se reduce la cantidad de múltiplos como es de esperar, pero el efecto negativo del PA lleva a su efecto neto sea negativo.

\begin{table}[H]
\caption{Detalle de la precisión para GMHAOV y GCE al aplicar PA para RR Lyrae.}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
Prueba & Match & Multiplo & Submultiplo & Alias & Other \\ \hline
GMHAOV & 90.35 & 0.75 & 0.1 & 1.45 & 7.35 \\ \hline
\begin{tabular}[c]{@{}c@{}}GMHAOV\\ con PA\end{tabular} & 90.40 & 0.25 & 0.20 & 1.75 & 7.40 \\ \hline
GCE & 58.80 & 2.10 & 4.45 & 3.60 & 31.05 \\ \hline
\begin{tabular}[c]{@{}c@{}}GCE\\ con PA\end{tabular} & 57.95 & 1.85 & 5.95 & 3.50 & 30.75 \\ \hline
\end{tabular}
\label{table:rrl-PA}
\end{table}

\subsubsection{Binarias Eclipsantes}
En el caso de las binarias eclipsantes, al aplicar PA la precisión incrementa más de 10 veces para GMHAOV y más de 3 veces para GCE. La cantidad de múltiplos se reduce significativamente, sin aumentar proporcionalmente la cantidad de submúltiplos.
\begin{table}[H]
\caption{Detalle de la precisión para GMHAOV y GCE al aplicar PA para binarias eclipsantes.}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
Prueba & Match & Multiplo & Submultiplo & Alias & Other \\ \hline
GMHAOV & 0.20 & 93.25 & 0.00 & 0.00 & 6.55 \\ \hline
\begin{tabular}[c]{@{}c@{}}GMHAOV\\ con PA\end{tabular} & 3.30 & 89.96 & 0.00 & 0.20 & 6.90 \\ \hline
GCE & 9.85 & 44.40 & 0.30 & 0.95 & 44.50 \\ \hline
\begin{tabular}[c]{@{}c@{}}GCE\\ con PA\end{tabular} & 32.30 & 21.85 & 0.85 & 1.40 & 43.60 \\ \hline
\end{tabular}
\label{table:eb-PA}
\end{table}

\section{Comparación de rendimiento}\label{sec:rendimiento}
Para la evaluación del rendimiento, se utilizó el generador de curvas de luz incluido en el repositorio de MHAOV, que permite generar curvas de luz con ruido simulado y una determinada cantidad de puntos fácilmente. Se evaluó el rendimiento de MHAOV, GMHAOV, GCE y el impacto del promediado de subarmónicos en el tiempo de ejecución de GMHAOV para $N=10,\ldots,10^{4}$ curvas de luz con $150$ puntos\footnote{El largo promedio de las curvas de luz de ALeRCE.} cada una y una resolución de frecuencias de $\text{fres}=10^{-2}, 10^{-3}, 10^{-4}$ y $10^{-5}$ desde las frecuencias $0.2$ a $0.9$. MHAOV se ejecuta de manera completamente secuencial para poder tener una medición adecuada del speedup.

Para cada combinación de valores de prueba, se mide el tiempo de ejecución de MHAOV, GMHAOV, GCE y el promediado de subarmónicos. Los resultados se encuentran en la figura \ref{fig:benchmarks}. El tiempo de ejecución por curva de luz se muestra en la Figura \ref{fig:benchmark-por-curva}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figs/benchmarks-total.png}
    \caption{Resultados de las pruebas para cada combinación de frecuencias y número de curvas de luz simultaneas. La línea punteada representa el tiempo de ejecución de MHAOV sumado al tiempo de ejecución del promediado de subarmónicos.}
    \label{fig:benchmarks}
\end{figure}

\begin{figure}[H]

    \centering
    \includegraphics[width=0.8\textwidth]{figs/benchmarks.png}
    \caption{Tiempo de ejecución por curva para cada combinación de frecuencias y número de curvas de luz simultaneas.}
\label{fig:benchmark-por-curva}
\end{figure}

 Para todas las resoluciones de frecuencia, GMHAOV es considerablemente más rápido que MHAOV, y comparable con GCE. Sin embargo, si se le suma el tiempo de ejecución del promediado de subarmónicos, el tiempo de ejecución de GMHAOV es comparable al de su versión secuencial (ver Figura \ref{fig:benchmarks}), pero sigue siendo menor. De todas maneras, para una alta resolución de frecuencias se logra un speedup de $1.5$ y de casi $10$ para resoluciones más bajas.

Esta tendencia queda más clara con la Figura \ref{fig:benchmark-por-curva}, donde para resoluciones de frecuencia más bajas el tiempo por curva de MHAOV llega a ser mejor que el de GCE, pero a medida que aumenta la resolución de frecuencia la eficiencia por curva de  MHAOV se hace cada vez menor, con GMHAOV representando una mejora sustancial del tiempo de ejecución por curva.

Es importante destacar, sin embargo, que el tiempo de ejecución de tanto GMHAOV como el de promediado de subarmónicos depende de la cantidad de curvas de una forma casi lineal, y tiene una dependencia más fuerte de la cantidad de frecuencias de prueba, como se observa en la Figura \ref{fig:benchmark-frecuencias-prueba}. El tiempo de ejecución por curva y por frecuencia de prueba de GCE disminuye con mayor rapidez que GMHAOV, como se nota en la Figura \ref{fig:benchmark-frecuencias-prueba}, lo que explica su mejor desempeño a mayor resolución frecuencial.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figs/benchmarks-frequency.png}
    \caption{Variación del tiempo de ejecución por curva y por frecuencia de prueba en función de la cantidad de frecuencia de pruebas para $N=10^{4}$}
    \label{fig:benchmark-frecuencias-prueba}
\end{figure}

Si se ejecuta MHAOV de forma paralela en CPU, dividiendo todas las curvas en 8 tandas y ejecutandolas en 8 núcleos separados, se obtienen los resultados de las figuras \ref{fig:benchmarks-total-8c}, \ref{fig:benchmark-8c} y \ref{fig:benchmark-frecuencias-prueba-8c}. En la Figura \ref{fig:benchmarks-8c}, para un número de curvas del orden de $10^{-4}$, tiempo de ejecución de MHAOV es comparable con el de GMHAOV a partir de las 700 frecuencias de prueba, rango en el que está el número de frecuencias de prueba usadas en la práctica. La razón de esto queda más claro en la Figura \ref{fig:benchmarks-por-curva-8c}, donde se observa que para resoluciones de frecuencia más altas, MHAOV tiene un menor tiempo de ejecución por curva que GMHAOV. Finalmente, en la figura \ref{fig:benchmark-frecuencias-prueba-8c}, el tiempo de ejecución por curva por frecuencia de prueba disminuye más rápido para MHAOV que para GMHAOV, pero no es claro si esta tendencia continua para un mayor número de frecuencias de prueba.
\begin{figure}[h]

    \centering
    \includegraphics[width=0.8\textwidth]{figs/benchmarks-8c.png}
    \caption{Tiempo de ejecución por curva para cada combinación de frecuencias y número de curvas de luz simultaneas, introduciendo paralelismo en MHAOV.}
    \label{fig:benchmarks-por-curva-8c}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figs/benchmarks-total-8c.png}
    \caption{Tiempo de ejecución total para cada combinación de frecuencias y número de curvas de luz simultaneas, introduciendo paralelismo en MHAOV.}
    \label{fig:benchmarks-8c}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figs/benchmarks-frequency-8c.png}
    \caption{Variación del tiempo de ejecución por curva y por frecuencia de prueba en función de la cantidad de frecuencia de pruebas para $N=10^{4}$, introduciendo paralelismo en MHAOV.}
    \label{fig:benchmark-frecuencias-prueba-8c}
\end{figure}

%\section{Pruebas con el clasificador de ALeRCE}\label{chap:clasificador-pruebas}
%Se hizo un crossmatch entre los objetos correspondientes a las curvas de luz con las que se realizaron las pruebas anteriores y los arreglos con sus clases reales y características calculadas con las cuales se entrenó el clasificador de ALeRCE \cite{p_sanchez_saez_2020_4279623}. El propósito de esto es entrenar el clasificador con los resultados del promediado de subarmónicos y GCE, y evaluar el impacto en el clasificador al incluir características adicionales, lo que puede ser viable si GMHAOV representa una disminución considerable del tiempo de ejecución.




\chapter{Análisis y conclusión}\label{chap:conclusión}

En este capítulo se concluye partir de los resultados, y se discute el trabajo futuro.

\section{Análisis de los resultados}\label{sec:analisis}

Es de gran importancia determinar qué características de las curvas de luz problemáticas descritas en \ref{sec:validacion} causan la diferencia en los periodogramas obtenidos por MHAOV y su versión en GPU. Sin embargo, el efecto de esta diferencia, si bien es significativo, no cambia completamente los resultados del periodograma, al menos con los tipos de curvas con las que se hicieron pruebas.

De los resultados de la sección \ref{sec:efectos-subarmonicos}, se observa que considerar el PS o PA puede ser beneficioso en algunos casos, si se incluye el puntaje asociado a la frecuencia corregida, calculado en el Código \ref{code:ps-2}, como característica en el clasificador. Este podrá aprender a discriminar en que situaciones es bueno considerar este puntaje y en cuales se puede ignorar. %Además, por lo descrito en \ref{sec:rendimiento}, GMHAOV es una mejora tan significativa que si se incluye el cálculo de estos puntajes el tiempo de ejecución será menor al de MHAOV a menos que se procesen una cantidad de curvas del orden de $10^{4}$.

Además, por lo descrito en \ref{sec:rendimiento}, la reducción en tiempo de ejecución de GMHAOV con respecto a MHAOV es tal que el tiempo de cálculo de los puntajes sumado al de GMHAOV es siempre menor al de MHAOV a menos que se procesen una cantidad de curvas del orden de $10^{4}$ y se ejecute MHAOV de forma paralela con una CPU moderna. La decisión de implementar GMHAOV en el sistema de ALeRCE depende entonces de las capacidades de hardware de ALeRCE y de cuanto es posible optimizar GMHAOV.

De las pruebas de rendimiento se puede concluir que GMHAOV presenta un compromiso entre tiempo de ejecución y precisión del período recuperado superior a GCE, por lo que se espera sea un valioso aporte para el pipeline de ALeRCE. 

\section{Conclusión y trabajo futuro}\label{sec:conclusion}

En este trabajo se logró implementar un periodograma en GPU que es capaz de encontrar el período en un conjunto extenso de curvas de luz de forma paralela. Además se estudió un algoritmo que puede potencialmente identificar aquellos casos en que el máximo del periodograma corresponde a una señal falsa, por lo que el objetivo general fue cumplido. Sin embargo, por términos de tiempo no se lograron cumplir los objetivos $4$ y $5$, pues no se pudo evaluar el impacto de usar los resultados de GMHAOV, GCE, y los puntajes obtenidos usando PR y PA como características del clasificador de ALeRCE. Es difícil predecir el impacto que tendrían la inclusión de estas estadísticas en el clasificador, ya que es un algoritmo de machine learning, pero si este algoritmo logra aprender cuando darle más peso a cada una de estas características, la mejora en la clasificación podría ser significativa para las clases relevantes.

A pesar de que el efecto de las imprecisiones en GMHAOV que no está presente en su versión secuencial no sea severo, es importante identificar su causa pues puede serlo para objetos en los que no se realizaron pruebas y afectar el proceso de clasificación. Si es que se logra encontrar la causa de los problemas mencionados, se debe llevar a cabo la implementación y testing de GMHAOV en el sistema de ALeRCE. Esto puede ser relativamente simple, ya que GMHAOV ofrece una interfaz en Python similar a la de MHAOV, pero se requeriría una validación más profunda del algoritmo.

También es importante notar que la manera en la que GMHAOV paraleliza el algoritmo requiere una gran sincronización a nivel de bloque, lo que implica un impacto en la eficiencia de la implementación. Es importante considerar en el futuro una implementación como la de GCE, descrita en la Sección \ref{sec:gce}, donde cada thread procesa una curva de luz, en vez de procesar cada curva a nivel de bloque. La ventaja de esto sería que se vuelve innecesario sincronizar los bloques, pero cada thread debe realizar muchos más cálculos.

Finalmente, debido a que GMHAOV tiene un speedup significativo, estudiar el efecto del número de armónicos usados en el cálculo del periodograma tanto en su precisión como en su eficiencia puede solucionar el problema de la precisión sin un impacto muy grande en el tiempo de ejecución. Sin embargo, es importante considerar que quizás sea posible optimizar aún más GMHAOV y obtener mejores resultados al compararlo con MHAOV ejecutado en CPU.

\bibliography{refs}
